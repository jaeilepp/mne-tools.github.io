

.. _sphx_glr_auto_examples_inverse_plot_rap_music.py:


================================
Compute Rap-Music on evoked data
================================

Compute a Recursively Applied and Projected MUltiple Signal Classification
(RAP-MUSIC) on evoked dataset.

The reference for Rap-Music is:
J.C. Mosher and R.M. Leahy. 1999. Source localization using recursively
applied and projected (RAP) MUSIC. Trans. Sig. Proc. 47, 2
(February 1999), 332-340.
DOI=10.1109/78.740118 http://dx.doi.org/10.1109/78.740118



.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_001.png
            :scale: 47

    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_002.png
            :scale: 47

    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_003.png
            :scale: 47

    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_004.png
            :scale: 47


.. rst-class:: sphx-glr-script-out

 Out::

    info["bads"] and noise_cov["bads"] do not match, excluding bad channels from both
        305 out of 366 channels remain after picking
        Created an SSP operator (subspace dimension = 3)
    estimated rank (mag + grad): 302
    Setting small MEG eigenvalues to zero.
    Not doing PCA for MEG.
    source 1 found: p = 1834
    ori = -0.247032414257 0.776432601466 0.579764953827
    source 2 found: p = 5304
    ori = -0.515459181377 0.534511689552 0.669775399717
    4 projection items deactivated
    Created an SSP operator (subspace dimension = 3)
    4 projection items activated
    SSP projectors applied...




|


.. code-block:: python


    # Author: Yousra Bekhti <yousra.bekhti@gmail.com>
    #
    # License: BSD (3-clause)

    import mne

    from mne.datasets import sample
    from mne.beamformer import rap_music
    from mne.viz import plot_dipole_locations, plot_dipole_amplitudes

    print(__doc__)

    data_path = sample.data_path()
    subjects_dir = data_path + '/subjects'
    fwd_fname = data_path + '/MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif'
    evoked_fname = data_path + '/MEG/sample/sample_audvis-ave.fif'
    cov_fname = data_path + '/MEG/sample/sample_audvis-cov.fif'

    # Read the evoked response and crop it
    condition = 'Right Auditory'
    evoked = mne.read_evokeds(evoked_fname, condition=condition,
                              baseline=(None, 0))
    evoked.crop(tmin=0.05, tmax=0.15)  # select N100

    evoked.pick_types(meg=True, eeg=False)

    # Read the forward solution
    forward = mne.read_forward_solution(fwd_fname, surf_ori=True,
                                        force_fixed=False)

    # Read noise covariance matrix
    noise_cov = mne.read_cov(cov_fname)

    dipoles, residual = rap_music(evoked, forward, noise_cov, n_dipoles=2,
                                  return_residual=True, verbose=True)
    trans = forward['mri_head_t']
    plot_dipole_locations(dipoles, trans, 'sample', subjects_dir=subjects_dir)
    plot_dipole_amplitudes(dipoles)

    # Plot the evoked data and the residual.
    evoked.plot(ylim=dict(grad=[-300, 300], mag=[-800, 800], eeg=[-6, 8]))
    residual.plot(ylim=dict(grad=[-300, 300], mag=[-800, 800], eeg=[-6, 8]))

**Total running time of the script:**
(0 minutes 9.954 seconds)



.. container:: sphx-glr-download

    **Download Python source code:** :download:`plot_rap_music.py <plot_rap_music.py>`


.. container:: sphx-glr-download

    **Download IPython notebook:** :download:`plot_rap_music.ipynb <plot_rap_music.ipynb>`
