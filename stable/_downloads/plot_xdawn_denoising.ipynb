{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n#  XDAWN Denoising\n\n\nXDAWN filters are trained from epochs, signal is projected in the sources\nspace and then projected back in the sensor space using only the first two\nXDAWN components. The process is similar to an ICA, but is\nsupervised in order to maximize the signal to signal + noise ratio of the\nevoked response.\n\nWARNING: As this denoising method exploits the known events to\nmaximize SNR of the contrast between conditions it can lead to overfit.\nTo avoid a statistical analysis problem you should split epochs used\nin fit with the ones used in apply method.\n\nReferences\n----------\n[1] Rivet, B., Souloumiac, A., Attina, V., & Gibert, G. (2009). xDAWN\nalgorithm to enhance evoked potentials: application to brain-computer\ninterface. Biomedical Engineering, IEEE Transactions on, 56(8), 2035-2043.\n\n[2] Rivet, B., Cecotti, H., Souloumiac, A., Maby, E., & Mattout, J. (2011,\nAugust). Theoretical analysis of xDAWN algorithm: application to an\nefficient sensor selection in a P300 BCI. In Signal Processing Conference,\n2011 19th European (pp. 1382-1386). IEEE.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Authors: Alexandre Barachant <alexandre.barachant@gmail.com>\n#\n# License: BSD (3-clause)\n\n\nfrom mne import (io, compute_raw_covariance, read_events, pick_types,\n                 Epochs)\nfrom mne.datasets import sample\nfrom mne.preprocessing import Xdawn\nfrom mne.viz import plot_epochs_image\n\nprint(__doc__)\n\ndata_path = sample.data_path()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Set parameters and read data\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\nevent_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\ntmin, tmax = -0.1, 0.3\nevent_id = dict(vis_r=4)\n\n# Setup for reading the raw data\nraw = io.read_raw_fif(raw_fname, preload=True)\nraw.filter(1, 20, method='iir')  # replace baselining with high-pass\nevents = read_events(event_fname)\n\nraw.info['bads'] = ['MEG 2443']  # set bad channels\npicks = pick_types(raw.info, meg=True, eeg=False, stim=False, eog=False,\n                   exclude='bads')\n# Epoching\nepochs = Epochs(raw, events, event_id, tmin, tmax, proj=False,\n                picks=picks, baseline=None, preload=True,\n                add_eeg_ref=False, verbose=False)\n\n# Plot image epoch before xdawn\nplot_epochs_image(epochs['vis_r'], picks=[230], vmin=-500, vmax=500)\n\n# Estimates signal covariance\nsignal_cov = compute_raw_covariance(raw, picks=picks)\n\n# Xdawn instance\nxd = Xdawn(n_components=2, signal_cov=signal_cov)\n\n# Fit xdawn\nxd.fit(epochs)\n\n# Denoise epochs\nepochs_denoised = xd.apply(epochs)\n\n# Plot image epoch after xdawn\nplot_epochs_image(epochs_denoised['vis_r'], picks=[230], vmin=-500, vmax=500)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.11", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}