{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Brainstorm auditory tutorial dataset\n\n\nHere we compute the evoked from raw for the auditory Brainstorm\ntutorial dataset. For comparison, see [1]_ and\nhttp://neuroimage.usc.edu/brainstorm/Tutorials/Auditory\n\nExperiment:\n    - One subject 2 acquisition runs 6 minutes each.\n    - Each run contains 200 regular beeps and 40 easy deviant beeps.\n    - Random ISI: between 0.7s and 1.7s seconds, uniformly distributed.\n    - Button pressed when detecting a deviant with the right index finger.\n\nThe specifications of this dataset were discussed initially on the FieldTrip\nbug tracker:\nhttp://bugzilla.fcdonders.nl/show_bug.cgi?id=2300\n\nReferences\n----------\n.. [1] Tadel F, Baillet S, Mosher JC, Pantazis D, Leahy RM.\n       Brainstorm: A User-Friendly Application for MEG/EEG Analysis.\n       Computational Intelligence and Neuroscience, vol. 2011, Article ID\n       879716, 13 pages, 2011. doi:10.1155/2011/879716\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Authors: Mainak Jas <mainak.jas@telecom-paristech.fr>\n#          Eric Larson <larson.eric.d@gmail.com>\n#          Jaakko Leppakangas <jaeilepp@student.jyu.fi>\n#\n# License: BSD (3-clause)\n\nimport os.path as op\nimport pandas as pd\nimport numpy as np\n\nimport mne\nfrom mne import combine_evoked\nfrom mne.minimum_norm import apply_inverse\nfrom mne.datasets.brainstorm import bst_auditory\nfrom mne.io import read_raw_ctf\nfrom mne.filter import notch_filter, low_pass_filter\n\nprint(__doc__)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "To reduce memory consumption and running time, some of the steps are\nprecomputed. To run everything from scratch change this to False. With\n``use_precomputed = False`` running time of this script can be several\nminutes even on a fast computer.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "use_precomputed = True"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "The data was collected with a CTF 275 system at 2400 Hz and low-pass\nfiltered at 600 Hz. Here the data and empty room data files are read to\nconstruct instances of :class:`mne.io.Raw`.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "data_path = bst_auditory.data_path()\n\nsubject = 'bst_auditory'\nsubjects_dir = op.join(data_path, 'subjects')\n\nraw_fname1 = op.join(data_path, 'MEG', 'bst_auditory',\n                     'S01_AEF_20131218_01.ds')\nraw_fname2 = op.join(data_path, 'MEG', 'bst_auditory',\n                     'S01_AEF_20131218_02.ds')\nerm_fname = op.join(data_path, 'MEG', 'bst_auditory',\n                    'S01_Noise_20131218_01.ds')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "In the memory saving mode we use ``preload=False`` and use the memory\nefficient IO which loads the data on demand. However, filtering and some\nother functions require the data to be preloaded in the memory.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "preload = not use_precomputed\nraw = read_raw_ctf(raw_fname1, preload=preload)\nn_times_run1 = raw.n_times\nmne.io.concatenate_raws([raw, read_raw_ctf(raw_fname2, preload=preload)])\nraw_erm = read_raw_ctf(erm_fname, preload=preload)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Data channel array consisted of 274 MEG axial gradiometers, 26 MEG reference\nsensors and 2 EEG electrodes (Cz and Pz).\nIn addition:\n  - 1 stim channel for marking presentation times for the stimuli\n  - 1 audio channel for the sent signal\n  - 1 response channel for recording the button presses\n  - 1 ECG bipolar\n  - 2 EOG bipolar (vertical and horizontal)\n  - 12 head tracking channels\n  - 20 unused channels\nThe head tracking channels and the unused channels are marked as misc\nchannels. Here we define the EOG and ECG channels.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "raw.set_channel_types({'HEOG': 'eog', 'VEOG': 'eog', 'ECG': 'ecg'})\nif not use_precomputed:\n    # Leave out the two EEG channels for easier computation of forward.\n    raw.pick_types(meg=True, eeg=False, stim=True, misc=True, eog=True,\n                   ecg=True)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "For noise reduction, a set of bad segments have been identified and stored\nin csv files. The bad segments are later used to reject epochs that overlap\nwith them.\nThe file for the second run also contains some saccades. The saccades are\nremoved by using SSP. We use pandas to read the data from the csv files. You\ncan also view the files with your favorite text editor.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "annotations_df = pd.DataFrame()\noffset = n_times_run1\nfor idx in [1, 2]:\n    csv_fname = op.join(data_path, 'MEG', 'bst_auditory',\n                        'events_bad_0%s.csv' % idx)\n    df = pd.read_csv(csv_fname, header=None,\n                     names=['onset', 'duration', 'id', 'label'])\n    print('Events from run {0}:'.format(idx))\n    print(df)\n\n    df['onset'] += offset * (idx - 1)\n    annotations_df = pd.concat([annotations_df, df], axis=0)\n\nsaccades_events = df[df['label'] == 'saccade'].values[:, :3].astype(int)\n\n# Conversion from samples to times:\nonsets = annotations_df['onset'].values / raw.info['sfreq']\ndurations = annotations_df['duration'].values / raw.info['sfreq']\ndescriptions = map(str, annotations_df['label'].values)\n\nannotations = mne.Annotations(onsets, durations, descriptions)\nraw.annotations = annotations\ndel onsets, durations, descriptions"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Here we compute the saccade and EOG projectors for magnetometers and add\nthem to the raw data. The projectors are added to both runs.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "saccade_epochs = mne.Epochs(raw, saccades_events, 1, 0., 0.5, preload=True,\n                            reject_by_annotation=False)\n\nprojs_saccade = mne.compute_proj_epochs(saccade_epochs, n_mag=1, n_eeg=0,\n                                        desc_prefix='saccade')\nif use_precomputed:\n    proj_fname = op.join(data_path, 'MEG', 'bst_auditory',\n                         'bst_auditory-eog-proj.fif')\n    projs_eog = mne.read_proj(proj_fname)[0]\nelse:\n    projs_eog, _ = mne.preprocessing.compute_proj_eog(raw.load_data(),\n                                                      n_mag=1, n_eeg=0)\nraw.add_proj(projs_saccade)\nraw.add_proj(projs_eog)\ndel saccade_epochs, saccades_events, projs_eog, projs_saccade  # To save memory"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Visually inspect the effects of projections. Click on 'proj' button at the\nbottom right corner to toggle the projectors on/off. EOG events can be\nplotted by adding the event list as a keyword argument. As the bad segments\nand saccades were added as annotations to the raw data, they are plotted as\nwell.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "raw.plot(block=True)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Typical preprocessing step is the removal of power line artifact (50 Hz or\n60 Hz). Here we notch filter the data at 60, 120 and 180 to remove the\noriginal 60 Hz artifact and the harmonics. The power spectra are plotted\nbefore and after the filtering to show the effect. The drop after 600 Hz\nappears because the data was filtered during the acquisition. In memory\nsaving mode we do the filtering at evoked stage, which is not something you\nusually would do.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if not use_precomputed:\n    meg_picks = mne.pick_types(raw.info, meg=True, eeg=False)\n    raw.plot_psd(picks=meg_picks)\n    notches = np.arange(60, 181, 60)\n    raw.notch_filter(notches)\n    raw.plot_psd(picks=meg_picks)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We also lowpass filter the data at 100 Hz to remove the hf components.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if not use_precomputed:\n    raw.filter(None, 100.)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Epoching and averaging.\nFirst some parameters are defined and events extracted from the stimulus\nchannel (UPPT001). The rejection thresholds are defined as peak-to-peak\nvalues and are in T / m for gradiometers, T for magnetometers and\nV for EOG and EEG channels.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "tmin, tmax = -0.1, 0.5\nevent_id = dict(standard=1, deviant=2)\nreject = dict(mag=4e-12, eog=250e-6)\n# find events\nevents = mne.find_events(raw, stim_channel='UPPT001')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "The event timing is adjusted by comparing the trigger times on detected\nsound onsets on channel UADC001-4408.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "sound_data = raw[raw.ch_names.index('UADC001-4408')][0][0]\nonsets = np.where(np.abs(sound_data) > 2. * np.std(sound_data))[0]\nmin_diff = int(0.5 * raw.info['sfreq'])\ndiffs = np.concatenate([[min_diff + 1], np.diff(onsets)])\nonsets = onsets[diffs > min_diff]\nassert len(onsets) == len(events)\ndiffs = 1000. * (events[:, 0] - onsets) / raw.info['sfreq']\nprint('Trigger delay removed (\u03bc \u00b1 \u03c3): %0.1f \u00b1 %0.1f ms'\n      % (np.mean(diffs), np.std(diffs)))\nevents[:, 0] = onsets\ndel sound_data, diffs"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We mark a set of bad channels that seem noisier than others. This can also\nbe done interactively with ``raw.plot`` by clicking the channel name\n(or the line). The marked channels are added as bad when the browser window\nis closed.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "raw.info['bads'] = ['MLO52-4408', 'MRT51-4408', 'MLO42-4408', 'MLO43-4408']"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "The epochs (trials) are created for MEG channels. First we find the picks\nfor MEG and EOG channels. Then the epochs are constructed using these picks.\nThe epochs overlapping with annotated bad segments are also rejected by\ndefault. To turn off rejection by bad segments (as was done earlier with\nsaccades) you can use keyword ``reject_by_annotation=False``.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "picks = mne.pick_types(raw.info, meg=True, eeg=False, stim=False, eog=True,\n                       exclude='bads')\n\nepochs = mne.Epochs(raw, events, event_id, tmin, tmax, picks=picks,\n                    baseline=(None, 0), reject=reject, preload=False,\n                    proj=True)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We only use first 40 good epochs from each run. Since we first drop the bad\nepochs, the indices of the epochs are no longer same as in the original\nepochs collection. Investigation of the event timings reveals that first\nepoch from the second run corresponds to index 182.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "epochs.drop_bad()\nepochs_standard = mne.concatenate_epochs([epochs['standard'][range(40)],\n                                          epochs['standard'][182:222]])\nepochs_standard.load_data()  # Resampling to save memory.\nepochs_standard.resample(600, npad='auto')\nepochs_deviant = epochs['deviant'].load_data()\nepochs_deviant.resample(600, npad='auto')\ndel epochs, picks"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "The averages for each conditions are computed.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "evoked_std = epochs_standard.average()\nevoked_dev = epochs_deviant.average()\ndel epochs_standard, epochs_deviant"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Typical preprocessing step is the removal of power line artifact (50 Hz or\n60 Hz). Here we notch filter the data at 60, 120 and 180 to remove the\noriginal 60 Hz artifact and the harmonics. Normally this would be done to\nraw data (with :func:`mne.io.Raw.filter`), but to reduce memory consumption\nof this tutorial, we do it at evoked stage.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if use_precomputed:\n    sfreq = evoked_std.info['sfreq']\n    nchan = evoked_std.info['nchan']\n    notches = [60, 120, 180]\n    for ch_idx in range(nchan):\n        evoked_std.data[ch_idx] = notch_filter(evoked_std.data[ch_idx], sfreq,\n                                               notches, verbose='ERROR')\n        evoked_dev.data[ch_idx] = notch_filter(evoked_dev.data[ch_idx], sfreq,\n                                               notches, verbose='ERROR')\n        evoked_std.data[ch_idx] = low_pass_filter(evoked_std.data[ch_idx],\n                                                  sfreq, 100, verbose='ERROR')\n        evoked_dev.data[ch_idx] = low_pass_filter(evoked_dev.data[ch_idx],\n                                                  sfreq, 100, verbose='ERROR')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Here we plot the ERF of standard and deviant conditions. In both conditions\nwe can see the P50 and N100 responses. The mismatch negativity is visible\nonly in the deviant condition around 100-200 ms. P200 is also visible around\n170 ms in both conditions but much stronger in the standard condition. P300\nis visible in deviant condition only (decision making in preparation of the\nbutton press). You can view the topographies from a certain time span by\npainting an area with clicking and holding the left mouse button.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "evoked_std.plot(window_title='Standard', gfp=True)\nevoked_dev.plot(window_title='Deviant', gfp=True)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Show activations as topography figures.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "times = np.arange(0.05, 0.301, 0.025)\nevoked_std.plot_topomap(times=times, title='Standard')\nevoked_dev.plot_topomap(times=times, title='Deviant')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We can see the MMN effect more clearly by looking at the difference between\nthe two conditions. P50 and N100 are no longer visible, but MMN/P200 and\nP300 are emphasised.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "evoked_difference = combine_evoked([evoked_dev, evoked_std], weights=[1, -1])\nevoked_difference.plot(window_title='Difference', gfp=True)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Source estimation.\nWe compute the noise covariance matrix from the empty room measurement\nand use it for the other runs.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "reject = dict(mag=4e-12)\ncov = mne.compute_raw_covariance(raw_erm, reject=reject)\ncov.plot(raw_erm.info)\ndel raw_erm"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "The transformation is read from a file. More information about coregistering\nthe data, see :ref:`ch_interactive_analysis` or\n:func:`mne.gui.coregistration`.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "trans_fname = op.join(data_path, 'MEG', 'bst_auditory',\n                      'bst_auditory-trans.fif')\ntrans = mne.read_trans(trans_fname)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "To save time and memory, the forward solution is read from a file. Set\n``use_precomputed=False`` in the beginning of this script to build the\nforward solution from scratch. The head surfaces for constructing a BEM\nsolution are read from a file. Since the data only contains MEG channels, we\nonly need the inner skull surface for making the forward solution. For more\ninformation: :ref:`CHDBBCEJ`, :class:`mne.setup_source_space`,\n:ref:`create_bem_model`, :func:`mne.bem.make_watershed_bem`.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if use_precomputed:\n    fwd_fname = op.join(data_path, 'MEG', 'bst_auditory',\n                        'bst_auditory-meg-oct-6-fwd.fif')\n    fwd = mne.read_forward_solution(fwd_fname)\nelse:\n    src = mne.setup_source_space(subject, spacing='ico4',\n                                 subjects_dir=subjects_dir, overwrite=True)\n    model = mne.make_bem_model(subject=subject, ico=4, conductivity=[0.3],\n                               subjects_dir=subjects_dir)\n    bem = mne.make_bem_solution(model)\n    fwd = mne.make_forward_solution(evoked_std.info, trans=trans, src=src,\n                                    bem=bem)\n\ninv = mne.minimum_norm.make_inverse_operator(evoked_std.info, fwd, cov)\nsnr = 3.0\nlambda2 = 1.0 / snr ** 2\ndel fwd"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "The sources are computed using dSPM method and plotted on an inflated brain\nsurface. For interactive controls over the image, use keyword\n``time_viewer=True``.\nStandard condition.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "stc_standard = mne.minimum_norm.apply_inverse(evoked_std, inv, lambda2, 'dSPM')\nbrain = stc_standard.plot(subjects_dir=subjects_dir, subject=subject,\n                          surface='inflated', time_viewer=False, hemi='lh')\nbrain.set_data_time_index(120)\ndel stc_standard, evoked_std, brain"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Deviant condition.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "stc_deviant = mne.minimum_norm.apply_inverse(evoked_dev, inv, lambda2, 'dSPM')\nbrain = stc_deviant.plot(subjects_dir=subjects_dir, subject=subject,\n                         surface='inflated', time_viewer=False, hemi='lh')\nbrain.set_data_time_index(120)\ndel stc_deviant, evoked_dev, brain"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Difference.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "stc_difference = apply_inverse(evoked_difference, inv, lambda2, 'dSPM')\nbrain = stc_difference.plot(subjects_dir=subjects_dir, subject=subject,\n                            surface='inflated', time_viewer=False, hemi='lh')\nbrain.set_data_time_index(150)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.11", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}