<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Decoding &mdash; MNE 0.12.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootswatch-3.3.4/flatly/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/style.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.12.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.4/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="top" title="MNE 0.12.0 documentation" href="../index.html" />
    <link rel="up" title="User Manual" href="index.html" />
    <link rel="next" title="Datasets" href="datasets_index.html" />
    <link rel="prev" title="Statistics" href="statistics.html" />

<link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,400,700' rel='stylesheet' type='text/css'>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37225609-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>



    <script type="text/javascript">
    !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);
    js.id=id;js.src="http://platform.twitter.com/widgets.js";
    fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
    </script>



    <script type="text/javascript">
    (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
    </script>


  </head>
  <body>





  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><img src="../_static/mne_logo_small.png">
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.12.0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../getting_started.html">Get started</a></li>
                <li><a href="../tutorials.html">Tutorials</a></li>
                <li><a href="../auto_examples/index.html">Gallery</a></li>
                <li><a href="../python_reference.html">API</a></li>
                <li><a href="index.html">Manual</a></li>
                <li><a href="../faq.html">FAQ</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contribute to MNE</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../python_reference.html">Python API Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../whats_new.html">What&#8217;s new</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cite.html">How to cite MNE</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">Related publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cited.html">Publications from MNE users</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Decoding</a><ul>
<li><a class="reference internal" href="#basic-estimators">Basic Estimators</a><ul>
<li><a class="reference internal" href="#scaler">Scaler</a></li>
<li><a class="reference internal" href="#epochsvectorizer">EpochsVectorizer</a></li>
<li><a class="reference internal" href="#psdestimator">PSDEstimator</a></li>
<li><a class="reference internal" href="#filterestimator">FilterEstimator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#spatial-filters">Spatial filters</a><ul>
<li><a class="reference internal" href="#common-spatial-pattern">Common Spatial Pattern</a></li>
<li><a class="reference internal" href="#xdawn">xDAWN</a></li>
<li><a class="reference internal" href="#effect-matched-spatial-filtering">Effect-matched spatial filtering</a></li>
<li><a class="reference internal" href="#patterns-vs-filters">Patterns vs. filters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sensor-space-decoding">Sensor-space decoding</a><ul>
<li><a class="reference internal" href="#generalization-across-time">Generalization Across Time</a></li>
<li><a class="reference internal" href="#time-decoding">Time Decoding</a></li>
</ul>
</li>
<li><a class="reference internal" href="#source-space-decoding">Source-space decoding</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/mne_logo_small.png" alt="Logo"/>
            </a></p><ul>
<li><a class="reference internal" href="#">Decoding</a><ul>
<li><a class="reference internal" href="#basic-estimators">Basic Estimators</a><ul>
<li><a class="reference internal" href="#scaler">Scaler</a></li>
<li><a class="reference internal" href="#epochsvectorizer">EpochsVectorizer</a></li>
<li><a class="reference internal" href="#psdestimator">PSDEstimator</a></li>
<li><a class="reference internal" href="#filterestimator">FilterEstimator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#spatial-filters">Spatial filters</a><ul>
<li><a class="reference internal" href="#common-spatial-pattern">Common Spatial Pattern</a></li>
<li><a class="reference internal" href="#xdawn">xDAWN</a></li>
<li><a class="reference internal" href="#effect-matched-spatial-filtering">Effect-matched spatial filtering</a></li>
<li><a class="reference internal" href="#patterns-vs-filters">Patterns vs. filters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sensor-space-decoding">Sensor-space decoding</a><ul>
<li><a class="reference internal" href="#generalization-across-time">Generalization Across Time</a></li>
<li><a class="reference internal" href="#time-decoding">Time Decoding</a></li>
</ul>
</li>
<li><a class="reference internal" href="#source-space-decoding">Source-space decoding</a></li>
</ul>
</li>
</ul>

  <li>
    <a href="statistics.html" title="Previous Chapter: Statistics"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Statistics</span>
    </a>
  </li>
  <li>
    <a href="datasets_index.html" title="Next Chapter: Datasets"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Datasets &raquo;</span>
    </a>
  </li>
<form action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="col-md-12">
      
  <div class="contents local topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#decoding" id="id2">Decoding</a><ul>
<li><a class="reference internal" href="#basic-estimators" id="id3">Basic Estimators</a><ul>
<li><a class="reference internal" href="#scaler" id="id4">Scaler</a></li>
<li><a class="reference internal" href="#epochsvectorizer" id="id5">EpochsVectorizer</a></li>
<li><a class="reference internal" href="#psdestimator" id="id6">PSDEstimator</a></li>
<li><a class="reference internal" href="#filterestimator" id="id7">FilterEstimator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#spatial-filters" id="id8">Spatial filters</a><ul>
<li><a class="reference internal" href="#common-spatial-pattern" id="id9">Common Spatial Pattern</a></li>
<li><a class="reference internal" href="#xdawn" id="id10">xDAWN</a></li>
<li><a class="reference internal" href="#effect-matched-spatial-filtering" id="id11">Effect-matched spatial filtering</a></li>
<li><a class="reference internal" href="#patterns-vs-filters" id="id12">Patterns vs. filters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sensor-space-decoding" id="id13">Sensor-space decoding</a><ul>
<li><a class="reference internal" href="#generalization-across-time" id="id14">Generalization Across Time</a></li>
<li><a class="reference internal" href="#time-decoding" id="id15">Time Decoding</a></li>
</ul>
</li>
<li><a class="reference internal" href="#source-space-decoding" id="id16">Source-space decoding</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="decoding">
<span id="id1"></span><h1><a class="toc-backref" href="#id2">Decoding</a><a class="headerlink" href="#decoding" title="Permalink to this headline">¶</a></h1>
<p>For maximal compatibility with the Scikit-learn package, we follow the same API. Each estimator implements a <tt class="docutils literal"><span class="pre">fit</span></tt>, a <tt class="docutils literal"><span class="pre">transform</span></tt> and a <tt class="docutils literal"><span class="pre">fit_transform</span></tt> method. In some cases, they also implement an <tt class="docutils literal"><span class="pre">inverse_transform</span></tt> method. For more details, visit the Scikit-learn page.</p>
<p>For ease of comprehension, we will denote instantiations of the class using the same name as the class but in small caps instead of camel cases.</p>
<div class="section" id="basic-estimators">
<h2><a class="toc-backref" href="#id3">Basic Estimators</a><a class="headerlink" href="#basic-estimators" title="Permalink to this headline">¶</a></h2>
<div class="section" id="scaler">
<h3><a class="toc-backref" href="#id4">Scaler</a><a class="headerlink" href="#scaler" title="Permalink to this headline">¶</a></h3>
<p>This will standardize data across channels. Each channel type (mag, grad or eeg) is treated separately. During training time, the mean (<cite>ch_mean_</cite>) and standard deviation (<cite>std_</cite>) is computed in the <tt class="docutils literal"><span class="pre">fit</span></tt> method and stored as an attribute to the object. The <tt class="docutils literal"><span class="pre">transform</span></tt> method is called to transform the training set. To perform both the <tt class="docutils literal"><span class="pre">fit</span></tt> and <tt class="docutils literal"><span class="pre">transform</span></tt> operations in a single call, the <tt class="docutils literal"><span class="pre">fit_transform</span></tt> method may be used. During test time, the stored mean and standard deviation are used in the <tt class="docutils literal"><span class="pre">transform</span></tt> method. To recover the original data, you can use <tt class="docutils literal"><span class="pre">inverse_transform</span></tt>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This is different from the <tt class="docutils literal"><span class="pre">StandarScaler</span></tt> estimator offered by Scikit-Learn. The <tt class="docutils literal"><span class="pre">StandardScaler</span></tt> standardizes each feature, whereas the <tt class="docutils literal"><span class="pre">Scaler</span></tt> object standardizes by channel type.</p>
</div>
</div>
<div class="section" id="epochsvectorizer">
<h3><a class="toc-backref" href="#id5">EpochsVectorizer</a><a class="headerlink" href="#epochsvectorizer" title="Permalink to this headline">¶</a></h3>
<p>Scikit-learn API enforces the requirement that data arrays must be 2D. A common strategy for sensor-space decoding is to tile the sensors into a single vector. This can be achieved using the function <a class="reference internal" href="../generated/mne.decoding.EpochsVectorizer.html#mne.decoding.EpochsVectorizer.transform" title="mne.decoding.EpochsVectorizer.transform"><tt class="xref py py-func docutils literal"><span class="pre">mne.decoding.EpochsVectorizer.transform()</span></tt></a>.</p>
<p>To recover the original 3D data, an <tt class="docutils literal"><span class="pre">inverse_transform</span></tt> can be used. The <tt class="docutils literal"><span class="pre">epochs_vectorizer</span></tt> is particularly useful when constructing a pipeline object (used mainly for parameter search and cross validation). The <tt class="docutils literal"><span class="pre">epochs_vectorizer</span></tt> is the first estimator in the pipeline enabling estimators downstream to be more advanced estimators implemented in Scikit-learn.</p>
</div>
<div class="section" id="psdestimator">
<h3><a class="toc-backref" href="#id6">PSDEstimator</a><a class="headerlink" href="#psdestimator" title="Permalink to this headline">¶</a></h3>
<p>This estimator computes the power spectral density (PSD) using the multitaper method. It takes a 3D array as input, it into 2D and computes the PSD.</p>
</div>
<div class="section" id="filterestimator">
<h3><a class="toc-backref" href="#id7">FilterEstimator</a><a class="headerlink" href="#filterestimator" title="Permalink to this headline">¶</a></h3>
<p>This estimator filters the 3D epochs data.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This is meant for use in conjunction with <tt class="docutils literal"><span class="pre">RtEpochs</span></tt>. It is not recommended in a normal processing pipeline as it may result in edge artifacts.</p>
</div>
</div>
</div>
<div class="section" id="spatial-filters">
<h2><a class="toc-backref" href="#id8">Spatial filters</a><a class="headerlink" href="#spatial-filters" title="Permalink to this headline">¶</a></h2>
<p>Just like temporal filters, spatial filters provide weights to modify the data along the sensor dimension. They are popular in the BCI community because of their simplicity and ability to distinguish spatially-separated neural activity.</p>
<div class="section" id="common-spatial-pattern">
<h3><a class="toc-backref" href="#id9">Common Spatial Pattern</a><a class="headerlink" href="#common-spatial-pattern" title="Permalink to this headline">¶</a></h3>
<p>This is a technique to analyze multichannel data based on recordings from two classes. Let <span class="math">\(X \in R^{C\times T}\)</span> be a segment of data with <span class="math">\(C\)</span> channels and <span class="math">\(T\)</span> time points. The data at a single time point is denoted by <span class="math">\(x(t)\)</span> such that <span class="math">\(X=[x(t), x(t+1), ..., x(t+T-1)]\)</span>. Common Spatial Pattern (CSP) finds a decomposition that projects the signal in the original sensor space to CSP space using the following transformation:</p>
<div class="math" id="equation-csp">
<span class="eqno">(1)</span>\[x_{CSP}(t) = W^{T}x(t)\]</div>
<p>where each column of <span class="math">\(W \in R^{C\times C}\)</span> is a spatial filter and each row of <span class="math">\(x_{CSP}\)</span> is a CSP component. The matrix <span class="math">\(W\)</span> is also called the de-mixing matrix in other contexts. Let <span class="math">\(\Sigma^{+} \in R^{C\times C}\)</span> and <span class="math">\(\Sigma^{-} \in R^{C\times C}\)</span> be the estimates of the covariance matrices of the two conditions.
CSP analysis is given by the simultaneous diagonalization of the two covariance matrices</p>
<div class="math" id="equation-diagonalize_p">
<span class="eqno">(2)</span>\[W^{T}\Sigma^{+}W = \lambda^{+}\]</div>
<div class="math" id="equation-diagonalize_n">
<span class="eqno">(3)</span>\[W^{T}\Sigma^{-}W = \lambda^{-}\]</div>
<p>where <span class="math">\(\lambda^{C}\)</span> is a diagonal matrix whose entries are the eigenvalues of the following generalized eigenvalue problem</p>
<div class="math" id="equation-eigen_problem">
<span class="eqno">(4)</span>\[\Sigma^{+}w = \lambda \Sigma^{-}w\]</div>
<p>Large entries in the diagonal matrix corresponds to a spatial filter which gives high variance in one class but low variance in the other. Thus, the filter facilitates discrimination between the two classes.</p>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_csp_eeg.html#sphx-glr-auto-examples-decoding-plot-decoding-csp-eeg-py"><em>Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</em></a></li>
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_csp_space.html#sphx-glr-auto-examples-decoding-plot-decoding-csp-space-py"><em>Decoding in sensor space data using the Common Spatial Pattern (CSP)</em></a></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">Spotlight:</p>
<p>The winning entry of the Grasp-and-lift EEG competition in Kaggle uses the CSP implementation in MNE. It was featured as a <a class="reference external" href="http://blog.kaggle.com/2015/08/12/july-2015-scripts-of-the-week/">script of the week</a>.</p>
</div>
</div>
<div class="section" id="xdawn">
<h3><a class="toc-backref" href="#id10">xDAWN</a><a class="headerlink" href="#xdawn" title="Permalink to this headline">¶</a></h3>
<p>Xdawn is a spatial filtering method designed to improve the signal to signal + noise ratio (SSNR) of the ERP responses. Xdawn was originally  designed for P300 evoked potential by enhancing the target response with respect to the non-target response. The implementation in MNE-Python is a generalization to any type of ERP.</p>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/preprocessing/plot_xdawn_denoising.html#sphx-glr-auto-examples-preprocessing-plot-xdawn-denoising-py"><em>XDAWN Denoising</em></a></li>
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_xdawn_eeg.html#sphx-glr-auto-examples-decoding-plot-decoding-xdawn-eeg-py"><em>XDAWN Decoding From EEG data</em></a></li>
</ul>
</div>
</div>
<div class="section" id="effect-matched-spatial-filtering">
<h3><a class="toc-backref" href="#id11">Effect-matched spatial filtering</a><a class="headerlink" href="#effect-matched-spatial-filtering" title="Permalink to this headline">¶</a></h3>
<p>The result is a spatial filter at each time point and a corresponding time course. Intuitively, the result gives the similarity between the filter at each time point and the data vector (sensors) at that time point.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_ems_filtering.html#sphx-glr-auto-examples-decoding-plot-ems-filtering-py"><em>Compute effect-matched-spatial filtering (EMS)</em></a></li>
</ul>
</div>
</div>
<div class="section" id="patterns-vs-filters">
<h3><a class="toc-backref" href="#id12">Patterns vs. filters</a><a class="headerlink" href="#patterns-vs-filters" title="Permalink to this headline">¶</a></h3>
<p>When interpreting the components of the CSP, it is often more intuitive to think about how <span class="math">\(x(t)\)</span> is composed of the different CSP components <span class="math">\(x_{CSP}(t)\)</span>. In other words, we can rewrite Equation <a href="#equation-csp">(1)</a> as follows:</p>
<div class="math" id="equation-patterns">
<span class="eqno">(5)</span>\[x(t) = (W^{-1})^{T}x_{CSP}(t)\]</div>
<p>The columns of the matrix <span class="math">\((W^{-1})^T\)</span> are called spatial patterns. This is also called the mixing matrix. The example <a class="reference internal" href="../auto_examples/decoding/plot_linear_model_patterns.html#sphx-glr-auto-examples-decoding-plot-linear-model-patterns-py"><em>Linear classifier on sensor data with plot patterns and filters</em></a> demonstrates the difference between patterns and filters.</p>
<p>Plotting a pattern is as simple as doing:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">info</span> <span class="o">=</span> <span class="n">epochs</span><span class="o">.</span><span class="n">info</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">plot_patterns</span><span class="p">(</span><span class="n">info</span><span class="p">)</span>  <span class="c1"># model is an instantiation of an estimator described in this section</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_linear_model_patterns_001.png"><img alt="manual/../../_images/sphx_glr_plot_linear_model_patterns_001.png" class="align-center" src="manual/../../_images/sphx_glr_plot_linear_model_patterns_001.png" style="height: 100px;" /></a>
<p>To plot the corresponding filter, you can do:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">plot_filters</span><span class="p">(</span><span class="n">info</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_linear_model_patterns_002.png"><img alt="manual/../../_images/sphx_glr_plot_linear_model_patterns_002.png" class="align-center" src="manual/../../_images/sphx_glr_plot_linear_model_patterns_002.png" style="height: 100px;" /></a>
</div>
</div>
<div class="section" id="sensor-space-decoding">
<h2><a class="toc-backref" href="#id13">Sensor-space decoding</a><a class="headerlink" href="#sensor-space-decoding" title="Permalink to this headline">¶</a></h2>
<div class="section" id="generalization-across-time">
<h3><a class="toc-backref" href="#id14">Generalization Across Time</a><a class="headerlink" href="#generalization-across-time" title="Permalink to this headline">¶</a></h3>
<p>Generalization Across Time (GAT) is a modern strategy to infer neuroscientific conclusions from decoding analysis of sensor-space data. An accuracy matrix is constructed where each point represents the performance of the model trained on one time window and tested on another.</p>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_decoding_time_generalization_001.png"><img alt="manual/../../_images/sphx_glr_plot_decoding_time_generalization_001.png" class="align-center" src="manual/../../_images/sphx_glr_plot_decoding_time_generalization_001.png" style="width: 400px;" /></a>
<p>To use this functionality, simply do:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">gat</span> <span class="o">=</span> <span class="n">GeneralizationAcrossTime</span><span class="p">(</span><span class="n">predict_mode</span><span class="o">=</span><span class="s1">&#39;cross-validation&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gat</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gat</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gat</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Generalization Across Time (faces vs. scrambled)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_ems_filtering.html#sphx-glr-auto-examples-decoding-plot-ems-filtering-py"><em>Compute effect-matched-spatial filtering (EMS)</em></a></li>
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_time_generalization_conditions.html#sphx-glr-auto-examples-decoding-plot-decoding-time-generalization-conditions-py"><em>Decoding sensor space data with generalization across time and conditions</em></a></li>
</ul>
</div>
</div>
<div class="section" id="time-decoding">
<h3><a class="toc-backref" href="#id15">Time Decoding</a><a class="headerlink" href="#time-decoding" title="Permalink to this headline">¶</a></h3>
<p>In this strategy, a model trained on one time window is tested on the same time window. A moving time window will thus yield an accuracy curve similar to an ERP, but is considered more sensitive to effects in some situations. It is related to searchlight-based approaches in fMRI. This is also the diagonal of the GAT matrix.</p>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_decoding_sensors_001.png"><img alt="manual/../../_images/sphx_glr_plot_decoding_sensors_001.png" class="align-center" src="manual/../../_images/sphx_glr_plot_decoding_sensors_001.png" style="width: 400px;" /></a>
<p>To generate this plot, you need to initialize a GAT object and then use the method <tt class="docutils literal"><span class="pre">plot_diagonal</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">gat</span><span class="o">.</span><span class="n">plot_diagonal</span><span class="p">()</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><em class="xref std std-ref">sphx_glr_auto_examples_decoding_plot_decoding_time_generalization.py</em></li>
</ul>
</div>
</div>
</div>
<div class="section" id="source-space-decoding">
<h2><a class="toc-backref" href="#id16">Source-space decoding</a><a class="headerlink" href="#source-space-decoding" title="Permalink to this headline">¶</a></h2>
<p>Source space decoding is also possible, but because the number of features can be much larger than in the sensor space, univariate feature selection using ANOVA f-test (or some other metric) can be done to reduce the feature dimension. Interpreting decoding results might be easier in source space as compared to sensor space.</p>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_spatio_temporal_source.html#sphx-glr-auto-examples-decoding-plot-decoding-spatio-temporal-source-py"><em>Decoding source space data</em></a></li>
</ul>
</div>
</div>
</div>


    </div>
    
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
      
    </p>
    <p>
        &copy; Copyright 2012-2016, MNE Developers. Last updated on 2016-05-11.<br/>
    </p>
  </div>
</footer>
  </body>
</html>